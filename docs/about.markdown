---
layout: page
title: About
permalink: /about/
---

Hello! I'm Arthur Conmy. I'm a Research Engineer at Google DeepMind, on the Language Model Interpretability team. I like to work on making interpretability useful, and am also thinking about thinking models and unfaithful Chain-of-Thought at the moment too.

I try and [read things]() sometimes too (sadly not updated in some time).

## Research 

**The below summary is highly outdated, and I have much more recent work from GDM and external in my <a href="https://scholar.google.com/citations?user=n4HIyXQAAAAJ">Google Scholar</a>**.

1. [<i> Copy Suppression: Comprehensively Understanding an Attention Head </i>](https://arxiv.org/abs/2310.04625)

   Callum McDougall,* <b>Arthur Conmy</b>,* Cody Rushing,* Thomas McGrath, Neel Nanda (* denotes equal contribution): arXiv preprint **arXiv:2310.04625** (2023)

   <img src="../assets/papers/copy_suppress.png" width="450">

2. [<i>Towards Automated Circuit Discovery for Mechanistic Interpretability</i>](https://arxiv.org/abs/2304.14997) 

   **Arthur Conmy,** AN Mavor-Parker, A Lynch, S Heimersheim, A Garriga-Alonso:
   NeurIPS 2023 Spotlight **arXiv:2304.14997** (2023)

   <img src="../assets/papers/acdc_finds_subgraph.png" width="450">

3. [<i>Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small</i>](https://arxiv.org/abs/2211.00593) 

   K Wang, A Variengien, **Arthur Conmy,** B Shlegeris, J Steinhardt  
   Proceedings of ICLR 2023 **arXiv:2211.00593**

   <img src="../assets/papers/ioi_circuit.png" width="450">

4. [<i>StyleGAN-induced data-driven regularization for inverse problems</i>](https://arxiv.org/abs/2110.03814)

   **Arthur Conmy,** S Mukherjee, CB Sch√∂nlieb  
   Proceedings of ICASSP 2022 **arXiv:2110.03814**

   <img src="../assets/papers/lbrgm.jpeg" width="450">

## Experience

<!-- <h3>Present: incoming Mechanistic Interpretability PhD student</h3> -->

<!-- (Currently doing Mechanistic Interpretability research under Neel Nanda. I'm an incoming PhD student) -->

<b>2023 - 2025 (present)</b> Research Engineer at Google DeepMind, on the Language Model Interpretability team.


<b>2023 - 2023</b> SERI MATS and Independent Research.


<b>2022 - 2023</b> <a href="https://www.redwoodresearch.org/">Redwood Research</a>.


<b>2021 - 2021</b> Meta. Software Engineering Intern.


<b>2019 - 2022</b> Trinity College Cambridge Undergraduate Mathematics. Upper first class honours.

<!-- ## Other things
Everything else is a <a href = "/">post</a>. -->

<img src="../assets/tower.jpeg">
Outside the Tower of London, July 2021.

For the future: 0ee063d506d9319ca159f53a7dd3879e65465e28926a02a35f9c6348ec00f1bf

<!-- [^fn1]: We put together a workshop on AI Safety too, loo. -->
<!-- <details><summary>Click to expand!</summary> Here is some more text</details> -->
<!-- [jekyll-organization]: https://github.com/jekyll -->
<!-- <html> -->
<!-- <body> -->
<!--  -->
<!-- {% include text-expand.html %} -->
<!-- </body> -->
<!-- </html> -->
